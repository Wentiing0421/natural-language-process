{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import requests, zipfile, io\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "import glob\n",
    "from glob import iglob\n",
    "from newspaper import Article\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import csv\n",
    "from langdetect import detect\n",
    "from time import ctime\n",
    "\n",
    "def process(df): #input filename\n",
    "    \"\"\"\n",
    "    Fetches news items from csv file\n",
    "    Returns a list of News.\n",
    "    \"\"\"\n",
    "    ret = []\n",
    "    for index,row in df.iterrows():\n",
    "        sqldate = row['SQLDATE']\n",
    "        month_year = row['MonthYear']\n",
    "        goldstein_scale = row['GoldsteinScale']\n",
    "        num_mentions = row['NumMentions']\n",
    "        num_sources = row['NumSources']\n",
    "        num_articles = row['NumArticles']\n",
    "        tone = row['AvgTone']\n",
    "        url = row['SOURCEURL']\n",
    "        news = News(sqldate, month_year, goldstein_scale, num_mentions, num_sources, num_articles, tone, url)\n",
    "        ret.append(news)\n",
    "    print('\\nThere are %d items in News.'% len(ret))\n",
    "    return ret\n",
    "\n",
    "def removeDuplicate (df):\n",
    "    date=df.sort_values(by='SQLDATE', ascending=True).groupby('SOURCEURL').first() [\"SQLDATE\"].reset_index().drop(['SOURCEURL'],axis=1)\n",
    "    by_data=df.groupby('SOURCEURL')['MonthYear','GoldsteinScale','NumMentions','NumSources','NumArticles','AvgTone'].mean().reset_index()\n",
    "    by_data['SQLDATE']=date\n",
    "    return by_data\n",
    "\n",
    "class News:\n",
    "    def __init__(self, sqldate, month_year, goldstein_scale, num_mentions, num_sources, num_articles, tone, url):\n",
    "        self.sqldate = sqldate\n",
    "        self.month_year = month_year\n",
    "        self.goldstein_scale = goldstein_scale\n",
    "        self.num_mentions = num_mentions\n",
    "        self.num_sources = num_sources\n",
    "        self.num_articles = num_articles\n",
    "        self.tone = tone\n",
    "        self.url = url\n",
    "        self.text = None\n",
    "        self.publish_date = None\n",
    "        self.taxonomy = []\n",
    "        self.language = []\n",
    "\n",
    "    def get_sqldate(self):\n",
    "        return self.sqldate\n",
    "    def get_monthyear(self):\n",
    "        return self.month_year\n",
    "    def get_goldsteinscale(self):\n",
    "        return self.goldstein_scale\n",
    "    def get_nummentions(self):\n",
    "        return self.num_mentions\n",
    "    def get_numsources(self):\n",
    "        return self.num_sources\n",
    "    def get_numarticles(self):\n",
    "        return self.num_articles\n",
    "    def get_tone(self):\n",
    "        return self.tone\n",
    "    def get_url(self):\n",
    "        return self.url\n",
    "    def get_text(self):\n",
    "        return self.text\n",
    "    def get_publish_date(self):\n",
    "        return self.publish_date\n",
    "    def get_taxonomy(self):\n",
    "        return self.taxonomy\n",
    "    def set_taxonomy(self,taxonomy):\n",
    "        self.taxonomy.extend(taxonomy)\n",
    "    def get_language(self):\n",
    "        return self.language\n",
    "    def set_language(self,language):\n",
    "        self.language.extend(language)\n",
    "    def clean_text(self):\n",
    "        try:\n",
    "            article = Article(self.url)\n",
    "            article.download()\n",
    "            article.parse()\n",
    "            self.text,self.publish_date = article.text, article.publish_date\n",
    "            print('Success.')\n",
    "        except:\n",
    "            self.text,self.publish_date = None, None\n",
    "            print('No text found.')\n",
    "\n",
    "\n",
    "# # Use these functonto save data to pickle\n",
    "\n",
    "# ### csvfilename:the csv file we downlaod(after sorting and seperate by month). for example: uk201606.csv\n",
    "# ### picklefilename:the name for pickle file. for example: uk201606data.p\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def pickle_cleaning(csvfilename,picklefilename):\n",
    "    data = removeDuplicate(pd.read_csv(csvfilename))\n",
    "    news_list = process(data)#change to class\n",
    "    pickle.dump(news_list, open(picklefilename,'wb'))#save as pickle\n",
    "    print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are 615 items in News.\n",
      "615\n",
      "\n",
      "There are 615 items in News.\n",
      "615\n",
      "\n",
      "There are 615 items in News.\n",
      "615\n",
      "\n",
      "There are 615 items in News.\n",
      "615\n",
      "\n",
      "There are 615 items in News.\n",
      "615\n",
      "\n",
      "There are 615 items in News.\n",
      "615\n",
      "\n",
      "There are 615 items in News.\n",
      "615\n",
      "\n",
      "There are 615 items in News.\n",
      "615\n",
      "\n",
      "There are 615 items in News.\n",
      "615\n",
      "\n",
      "There are 615 items in News.\n",
      "615\n",
      "\n",
      "There are 615 items in News.\n",
      "615\n",
      "\n",
      "There are 1495 items in News.\n",
      "1495\n"
     ]
    }
   ],
   "source": [
    "pickle_cleaning('ru201402.csv','ru201402.p')\n",
    "pickle_cleaning('ru201403.csv','ru201403.p')\n",
    "pickle_cleaning('ru201404.csv','ru201404.p')\n",
    "pickle_cleaning('ru201405.csv','ru201405.p')\n",
    "pickle_cleaning('ru201406.csv','ru201406.p')\n",
    "pickle_cleaning('ru201407.csv','ru201407.p')\n",
    "pickle_cleaning('ru201408.csv','ru201408.p')\n",
    "pickle_cleaning('ru201409.csv','ru201409.p')\n",
    "pickle_cleaning('ru201410.csv','ru201410.p')\n",
    "pickle_cleaning('ru201411.csv','ru201411.p')\n",
    "pickle_cleaning('ru201412.csv','ru201412.p')\n",
    "pickle_cleaning('ru201501.csv','ru201501.p')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
